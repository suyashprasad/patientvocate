# PatientVocate ğŸ©º

**AI-Powered Consultation Preparation Platform**

PatientVocate translates complex medical lab reports into clear, structured, and patient-friendly summaries. It helps patients understand their results and prepare for doctor visits with personalized discussion questions.

![PatientVocate Dashboard](https://via.placeholder.com/800x450.png?text=PatientVocate+Dashboard+Preview)

## ğŸš€ Features

- **ğŸ“„ Upload & Analyze**: Drag-and-drop PDF lab reports or paste text directly.
- **ğŸ§  AI-Powered Insights**: Choose between **Local (Ollama)** or **Cloud (Google Gemini)** models.
- **ğŸ”¬ Key Findings**: Automatically highlights Abnormal, Borderline, and Normal results.
- **ğŸ“– Medical Glossary**: Explains complex terminology simply.
- **ğŸ’¬ Follow-up Chat**: Ask questions about your report in a conversational interface ("What does high LDL mean for my diet?").
- **ğŸ”’ Privacy First**: Default to local processing for privacy, or switch to cloud for speed.

## ğŸ› ï¸ Tech Stack

- **Backend**: Java 17, Spring Boot 3.x, Apache PDFBox, Tess4J (OCR)
- **Frontend**: Angular 17+, TypeScript, Vanilla CSS (Premium Dark Theme)
- **AI**: Ollama (Mistral) / Google Gemini API

## ğŸ“‹ Prerequisites

Before running, ensure you have the following installed:

1.  **Java 17+** (JDK)
2.  **Node.js & npm** (v18+)
3.  **Ollama** (Running locally with Mistral model)
    ```bash
    ollama run mistral
    ```
4.  **Tesseract OCR** (Data files) - _Optional, for image support_
    -   **Windows**: Embedded in the application (tess4j bundles DLLs).
    -   **Linux/WSL**: You **MUST** install it manually:
        ```bash
        sudo apt update
        sudo apt install tesseract-ocr
        ```

## ğŸƒâ€â™‚ï¸ How to Run

### 1. Start the Backend (Spring Boot)

Open a terminal in the `backend` folder:

#### Windows
```bash
cd backend
./mvnw.cmd spring-boot:run
```

#### Linux / WSL / macOS
Since the project does not bundle the Maven Wrapper JAR, please install Maven manually:
```bash
# Ubuntu/Debian/WSL
sudo apt update
sudo apt install maven

# Run the app
cd backend
mvn spring-boot:run
```

The backend will start on `http://localhost:8080`.

### 2. Start the Frontend (Angular)

Open a new terminal in the `frontend` folder:

```bash
cd frontend
npm install
npm start
```

The application will be available at `http://localhost:4200`.

## ğŸ§ª Testing

1.  Open `http://localhost:4200` in your browser.
2.  **Select AI Provider**: Toggle between **Local (Ollama)** and **Cloud (Gemini)** in the header.
3.  **Upload/Paste**: Submit your report.
4.  **Analyze**: View results generated by your chosen AI model.
5.  **Chat**: Ask follow-ups contextually.

## âš ï¸ Troubleshooting

-   **"Connection Refused"**: Ensure the backend is running on port 8080.
-   **"AI Offline"**: Make sure Ollama is running (`ollama serve`). This indicator tracks local status.
-   **"Gemini Error"**: Verify your API key in `backend/src/main/resources/application.yml`.

---

**Disclaimer**: PatientVocate is for educational purposes only. It does not provide medical diagnosis or treatment advice. Always consult your healthcare provider.
